{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с датасетом кинетик нашел очень интересный фреймворк [FIFTYONE](https://docs.voxel51.com/). Попробуем использовать его в поставленной задаче. К сожалению, в нем еще очень много багов, и найденный [гайд](https://medium.com/voxel51/the-kinetics-dataset-train-and-evaluate-video-classification-models-1d26e699a9e7) по загрузке и классификации видео через flash(pytorch lightning) повторить/применить для нашей задачи не удалось. Поэтому будем использовать данный фреймворк только для скачивания нужных данных."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kirill\\Documents\\GitHub\\action_recognitiion\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fiftyone.zoo as foz\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_video\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 10\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зафиксируем сиды\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "set_seed(seed=SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание датасета"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала нужно получить список классов, содержащих слово **dancing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tap dancing',\n",
       " 'breakdancing',\n",
       " 'belly dancing',\n",
       " 'dancing charleston',\n",
       " 'dancing ballet',\n",
       " 'square dancing',\n",
       " 'jumpstyle dancing',\n",
       " 'salsa dancing',\n",
       " 'robot dancing',\n",
       " 'country line dancing',\n",
       " 'dancing macarena',\n",
       " 'mosh pit dancing',\n",
       " 'dancing gangnam style',\n",
       " 'swing dancing',\n",
       " 'tango dancing']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df = df[df['label'].str.contains('dancing')]\n",
    "class_values = df['label'].unique().tolist()\n",
    "class_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь загрузим видео, так как классов всего 15, то загрузим примерно по 20 видео на класс для обучения и примерно по 3 видео на класс для проверки. Получится 296 и 48, цифры берем такие, чтобы нацело делились на размер батча."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to 'videos\\train' if necessary\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'kinetics-700-2020-train-296'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "# Load Kinetics\n",
    "dataset_train = foz.load_zoo_dataset(\n",
    "    \"kinetics-700-2020\",\n",
    "    dataset_dir = \"videos\",\n",
    "    split=\"train\",\n",
    "    classes=class_values,\n",
    "    max_samples=296,\n",
    "    num_workers = -1,\n",
    "    shuffle = True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При первом запуске выдает ошибку, но скачивает при этом все необходимые видео. После того как видео скачено и при повторном запуске ячейке ошибки не выдается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to 'videos\\validation' if necessary\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading existing dataset 'kinetics-700-2020-validation-48'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "dataset_valid = foz.load_zoo_dataset(\n",
    "    \"kinetics-700-2020\",\n",
    "    dataset_dir = \"videos\",\n",
    "    split=\"validation\",\n",
    "    classes=class_values,\n",
    "    max_samples=48,\n",
    "    num_workers = -1,\n",
    "    shuffle = True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сделаем датафрейм, который будет содержать следующие колонки: **'path', 'class_str', 'target'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('videos', 'train')\n",
    "valid_dir = os.path.join('videos', 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(folder_name):\n",
    "    # сначала формируем списки файлов и другой доп инфы\n",
    "    all_paths = []\n",
    "    all_labels = []\n",
    "    all_targets = []\n",
    "    folders = sorted([f for f in os.listdir(folder_name) if os.path.isdir(os.path.join(folder_name, f))])\n",
    "\n",
    "    for i, folder in enumerate(folders):\n",
    "        temp_paths = [os.path.join(folder_name, folder, f) for f \n",
    "                      in os.listdir(os.path.join(folder_name, folder))]\n",
    "        \n",
    "        all_paths += temp_paths\n",
    "        all_labels += [str(folder)] * len(temp_paths)\n",
    "        all_targets += [i] * len(temp_paths)\n",
    "       \n",
    "    # сделаем датафрейм\n",
    "    df = pd.DataFrame({'path': all_paths,\n",
    "                       'class_str': all_labels,\n",
    "                       'target': all_targets})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = create_df(train_dir)\n",
    "df_valid = create_df(valid_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class_str</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>videos\\train\\tap dancing\\KwvMol8NsZQ_000035_00...</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>videos\\train\\tap dancing\\lR_t-6WxR_g_000070_00...</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>videos\\train\\tap dancing\\TlOXXxGDJKA_000016_00...</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>videos\\train\\tap dancing\\TTg2eg_lJ-o_000011_00...</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>videos\\train\\tap dancing\\yEoEK_KskJ4_000037_00...</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path    class_str  target\n",
       "291  videos\\train\\tap dancing\\KwvMol8NsZQ_000035_00...  tap dancing      14\n",
       "292  videos\\train\\tap dancing\\lR_t-6WxR_g_000070_00...  tap dancing      14\n",
       "293  videos\\train\\tap dancing\\TlOXXxGDJKA_000016_00...  tap dancing      14\n",
       "294  videos\\train\\tap dancing\\TTg2eg_lJ-o_000011_00...  tap dancing      14\n",
       "295  videos\\train\\tap dancing\\yEoEK_KskJ4_000037_00...  tap dancing      14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DanceDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        video_path = row['path']\n",
    "        target = row['target']\n",
    "\n",
    "        video, audio, info = read_video(video_path, pts_unit=\"sec\")\n",
    "        # Возьмем только часть кадров, чтобы сократить вычисления \n",
    "        if len(video) > 0:\n",
    "            if len(video) < 128:\n",
    "                video = video[:32] \n",
    "            else:\n",
    "                video = video[:128:4]\n",
    "\n",
    "            video = video.numpy()\n",
    "            video = torch.Tensor(video)\n",
    "            resize_transform = transforms.Resize((112, 112))\n",
    "            video_resized = torch.stack([resize_transform(frame.permute(2, 0, 1)).permute(1, 2, 0) for frame in video])\n",
    "            video_normalized = video_resized.permute(3, 0, 1, 2)\n",
    "            tensor_3d = video_normalized / 255 \n",
    "        else:\n",
    "            tensor_3d = torch.empty(3, 32, 112, 112)\n",
    "            \n",
    "        label = torch.tensor(target).long()\n",
    "        \n",
    "        return tensor_3d, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = DanceDataset(df_train.reset_index(drop=True))\n",
    "dataset_test = DanceDataset(df_valid.reset_index(drop=True))\n",
    "\n",
    "train_loader = DataLoader(dataset_train,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "valid_loader = DataLoader(dataset_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание модели и обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.video.r3d_18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 15)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, valid_loader):\n",
    "    start = time.time()\n",
    "    for epoch_i in range(1, EPOCHS + 1):\n",
    "\n",
    "        print(f'---------------------epoch:{epoch_i}/{EPOCHS}---------------------')\n",
    "\n",
    "        # loss\n",
    "        avg_train_loss = 0\n",
    "        avg_val_loss = 0\n",
    "        summa = 0\n",
    "\n",
    "        ############## Train #############\n",
    "        model.train()\n",
    "        train_pbar = tqdm(train_loader, desc=\"Training\")\n",
    "        for X, y in (train_pbar):\n",
    "            X_batch = X.to(device)\n",
    "            y_batch = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            res = model.forward(X_batch)\n",
    "        \n",
    "            loss = loss_f(res, y_batch)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                train_pbar.set_postfix(gpu_load=f\"{torch.cuda.memory_allocated() / 1024 ** 3:.2f}GB\",\n",
    "                                    loss=f\"{loss.item():.4f}\")\n",
    "            else:\n",
    "                train_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_train_loss += loss * len(y_batch)\n",
    "            \n",
    "            del X, res\n",
    "\n",
    "        ########## VALIDATION ###############\n",
    "        model.eval()\n",
    "        valid_pbar = tqdm(valid_loader, desc=\"Testing\")\n",
    "        with torch.no_grad():\n",
    "            for X, y in (valid_pbar):\n",
    "                X_batch = X.to(device)\n",
    "                y_batch = y.to(device)\n",
    "\n",
    "                res = model.forward(X_batch)\n",
    "                \n",
    "                loss = loss_f(res, y_batch)\n",
    "                avg_val_loss += loss * len(y_batch)\n",
    "                valid_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "                res = res.detach().cpu()\n",
    "                y_batch = y_batch.cpu()\n",
    "                \n",
    "                preds = torch.max(F.softmax(res, dim=1), dim=1)\n",
    "                correct= torch.eq(preds[1], y_batch)\n",
    "                summa += torch.sum(correct).item()\n",
    "\n",
    "                del X, res\n",
    "                \n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        avg_train_loss = avg_train_loss / len(dataset_train)\n",
    "        avg_val_loss = avg_val_loss / len(dataset_test)\n",
    "        acc = summa / len(dataset_test)\n",
    "\n",
    "        print(f'Epoch: {epoch_i}, lr_rate {optimizer.param_groups[0][\"lr\"]}')\n",
    "\n",
    "        print(\"Loss_train: %0.4f| Loss_valid: %0.4f|\" % (avg_train_loss, avg_val_loss))\n",
    "        print(\"ACC:\", acc)\n",
    "\n",
    "        torch.save(model, f\"model_ep_{epoch_i}.pt\")\n",
    "\n",
    "    elapsed_time = time.time() - start\n",
    "    hours = int(elapsed_time // 3600)\n",
    "    minutes = int((elapsed_time % 3600) // 60)\n",
    "    seconds = int(elapsed_time % 60)\n",
    "    print(f\"Elapsed total time: {hours:02d}:{minutes:02d}:{seconds:02d}\")\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------epoch:1/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [09:44<00:00, 15.80s/it, gpu_load=2.91GB, loss=1.7112]\n",
      "Testing: 100%|██████████| 6/6 [01:20<00:00, 13.49s/it, loss=2.4026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, lr_rate 0.0001\n",
      "Loss_train: 2.4356| Loss_valid: 2.2392|\n",
      "ACC: 0.25\n",
      "---------------------epoch:2/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [08:30<00:00, 13.81s/it, gpu_load=2.91GB, loss=1.1985]\n",
      "Testing: 100%|██████████| 6/6 [01:20<00:00, 13.35s/it, loss=1.6802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, lr_rate 0.0001\n",
      "Loss_train: 1.0702| Loss_valid: 2.0141|\n",
      "ACC: 0.375\n",
      "---------------------epoch:3/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [08:11<00:00, 13.29s/it, gpu_load=2.91GB, loss=0.4402]\n",
      "Testing: 100%|██████████| 6/6 [01:16<00:00, 12.75s/it, loss=1.8313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, lr_rate 0.0001\n",
      "Loss_train: 0.4797| Loss_valid: 2.0387|\n",
      "ACC: 0.3333333333333333\n",
      "---------------------epoch:4/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [08:06<00:00, 13.16s/it, gpu_load=2.91GB, loss=0.1970]\n",
      "Testing: 100%|██████████| 6/6 [01:22<00:00, 13.69s/it, loss=1.7125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, lr_rate 0.0001\n",
      "Loss_train: 0.2187| Loss_valid: 1.9436|\n",
      "ACC: 0.375\n",
      "---------------------epoch:5/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [09:01<00:00, 14.63s/it, gpu_load=2.91GB, loss=0.1351]\n",
      "Testing: 100%|██████████| 6/6 [01:19<00:00, 13.19s/it, loss=1.6633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, lr_rate 0.0001\n",
      "Loss_train: 0.1197| Loss_valid: 2.0018|\n",
      "ACC: 0.4166666666666667\n",
      "---------------------epoch:6/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [08:22<00:00, 13.58s/it, gpu_load=2.91GB, loss=0.0807]\n",
      "Testing: 100%|██████████| 6/6 [01:15<00:00, 12.58s/it, loss=1.9010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, lr_rate 0.0001\n",
      "Loss_train: 0.1016| Loss_valid: 2.0096|\n",
      "ACC: 0.3125\n",
      "---------------------epoch:7/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [08:25<00:00, 13.65s/it, gpu_load=2.91GB, loss=0.0449]\n",
      "Testing: 100%|██████████| 6/6 [01:18<00:00, 13.05s/it, loss=1.8808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, lr_rate 0.0001\n",
      "Loss_train: 0.0705| Loss_valid: 2.0001|\n",
      "ACC: 0.3958333333333333\n",
      "---------------------epoch:8/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [08:29<00:00, 13.77s/it, gpu_load=2.91GB, loss=0.0434]\n",
      "Testing: 100%|██████████| 6/6 [01:16<00:00, 12.76s/it, loss=2.2138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, lr_rate 0.0001\n",
      "Loss_train: 0.0631| Loss_valid: 2.0827|\n",
      "ACC: 0.3541666666666667\n",
      "---------------------epoch:9/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [08:32<00:00, 13.85s/it, gpu_load=2.91GB, loss=0.0359]\n",
      "Testing: 100%|██████████| 6/6 [01:20<00:00, 13.42s/it, loss=2.1420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, lr_rate 0.0001\n",
      "Loss_train: 0.0413| Loss_valid: 2.0356|\n",
      "ACC: 0.25\n",
      "---------------------epoch:10/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [08:26<00:00, 13.70s/it, gpu_load=2.91GB, loss=0.0171]\n",
      "Testing: 100%|██████████| 6/6 [01:18<00:00, 13.16s/it, loss=2.1276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, lr_rate 0.0001\n",
      "Loss_train: 0.0404| Loss_valid: 2.0524|\n",
      "ACC: 0.3125\n",
      "Elapsed total time: 01:39:04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_acc = train(model, optimizer, train_loader, valid_loader)\n",
    "model1_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сравним по метрике с другой моделью, которую предварительно тоже обучим. Обучать будем на отдельных кадрах в качестве модели возьмем `tf_efficientnetv2_s_in21k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DanceImgDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.aug =  A.Compose([\n",
    "            A.Resize(height=224, width=224, always_apply=True),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225],),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        video_path = row['path']\n",
    "        target = row['target']\n",
    "\n",
    "        video, audio, info = read_video(video_path, pts_unit=\"sec\")\n",
    "        # Берем случайный кадр \n",
    "        if len(video) > 0:\n",
    "            total_frames = video.shape[0]\n",
    "            random_frame_index = torch.randint(0, total_frames, (1,)).item()\n",
    "            random_frame = video[random_frame_index].numpy()\n",
    "            frame_with_aug = self.aug(image=random_frame)['image']\n",
    "            \n",
    "        else:\n",
    "            random_frame = torch.randint(0, 256, (244, 244, 3), dtype=torch.uint8).numpy()\n",
    "            frame_with_aug = self.aug(image=random_frame)['image']\n",
    "            \n",
    "        label = torch.tensor(target).long()\n",
    "        \n",
    "        return frame_with_aug, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = DanceImgDataset(df_train.reset_index(drop=True))\n",
    "dataset_test = DanceImgDataset(df_valid.reset_index(drop=True))\n",
    "\n",
    "train_loader = DataLoader(dataset_train,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "valid_loader = DataLoader(dataset_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('tf_efficientnetv2_s_in21k', pretrained=True)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(model.classifier.in_features, 15)\n",
    ")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------epoch:1/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [04:11<00:00,  6.80s/it, gpu_load=1.42GB, loss=2.7988]\n",
      "Testing: 100%|██████████| 6/6 [00:49<00:00,  8.27s/it, loss=2.5763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, lr_rate 0.0001\n",
      "Loss_train: 2.7128| Loss_valid: 2.6233|\n",
      "ACC: 0.14583333333333334\n",
      "---------------------epoch:2/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [04:53<00:00,  7.94s/it, gpu_load=1.42GB, loss=1.9292]\n",
      "Testing: 100%|██████████| 6/6 [00:53<00:00,  8.84s/it, loss=2.5702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, lr_rate 0.0001\n",
      "Loss_train: 2.3023| Loss_valid: 2.4527|\n",
      "ACC: 0.2708333333333333\n",
      "---------------------epoch:3/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [04:58<00:00,  8.07s/it, gpu_load=1.42GB, loss=2.0441]\n",
      "Testing: 100%|██████████| 6/6 [00:50<00:00,  8.37s/it, loss=2.7985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, lr_rate 0.0001\n",
      "Loss_train: 1.8802| Loss_valid: 2.4774|\n",
      "ACC: 0.14583333333333334\n",
      "---------------------epoch:4/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [04:48<00:00,  7.79s/it, gpu_load=1.42GB, loss=1.5762]\n",
      "Testing: 100%|██████████| 6/6 [00:45<00:00,  7.57s/it, loss=2.5455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, lr_rate 0.0001\n",
      "Loss_train: 1.5713| Loss_valid: 2.3814|\n",
      "ACC: 0.25\n",
      "---------------------epoch:5/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [04:52<00:00,  7.92s/it, gpu_load=1.42GB, loss=1.3514]\n",
      "Testing: 100%|██████████| 6/6 [00:50<00:00,  8.48s/it, loss=2.6042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, lr_rate 0.0001\n",
      "Loss_train: 1.3142| Loss_valid: 2.3736|\n",
      "ACC: 0.14583333333333334\n",
      "---------------------epoch:6/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [04:50<00:00,  7.85s/it, gpu_load=1.42GB, loss=1.2638]\n",
      "Testing: 100%|██████████| 6/6 [00:47<00:00,  7.87s/it, loss=2.2956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, lr_rate 0.0001\n",
      "Loss_train: 1.1241| Loss_valid: 2.3380|\n",
      "ACC: 0.1875\n",
      "---------------------epoch:7/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [04:42<00:00,  7.64s/it, gpu_load=1.42GB, loss=0.8194]\n",
      "Testing: 100%|██████████| 6/6 [00:49<00:00,  8.17s/it, loss=2.3588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, lr_rate 0.0001\n",
      "Loss_train: 0.8955| Loss_valid: 2.3321|\n",
      "ACC: 0.25\n",
      "---------------------epoch:8/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [05:22<00:00,  8.73s/it, gpu_load=1.42GB, loss=1.2200]\n",
      "Testing: 100%|██████████| 6/6 [00:50<00:00,  8.34s/it, loss=2.0568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, lr_rate 0.0001\n",
      "Loss_train: 0.7997| Loss_valid: 2.0698|\n",
      "ACC: 0.3541666666666667\n",
      "---------------------epoch:9/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [04:44<00:00,  7.68s/it, gpu_load=1.42GB, loss=0.7231]\n",
      "Testing: 100%|██████████| 6/6 [00:47<00:00,  7.91s/it, loss=2.4321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, lr_rate 0.0001\n",
      "Loss_train: 0.5929| Loss_valid: 2.3486|\n",
      "ACC: 0.25\n",
      "---------------------epoch:10/10---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 37/37 [04:50<00:00,  7.85s/it, gpu_load=1.42GB, loss=0.7106]\n",
      "Testing: 100%|██████████| 6/6 [00:50<00:00,  8.40s/it, loss=2.1984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, lr_rate 0.0001\n",
      "Loss_train: 0.5143| Loss_valid: 2.1798|\n",
      "ACC: 0.2708333333333333\n",
      "Elapsed total time: 00:56:31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2708333333333333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_acc = train(model, optimizer, train_loader, valid_loader)\n",
    "model2_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тяжело делать выводы на основе этих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
